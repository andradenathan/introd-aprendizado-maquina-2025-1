{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Experimentação no laboratório de Machine Learning\n",
        "\n",
        "#### Construção do modelo de Regressão Logística para o dataset Iris"
      ],
      "metadata": {
        "id": "giErJCCsmZ7t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "XNKY7oOWmVZ4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target"
      ],
      "metadata": {
        "id": "3hrd-1DVm-hY"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "minmax_scaler = MinMaxScaler()\n",
        "X_normalized = minmax_scaler.fit_transform(X)\n",
        "\n",
        "standard_scaler = StandardScaler()\n",
        "X_standardized = standard_scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "ba5udGDunGvE"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_normalized_bias = np.c_[np.ones(X_normalized.shape[0]), X_normalized]\n",
        "X_standardized_bias = np.c_[np.ones(X_standardized.shape[0]), X_standardized]"
      ],
      "metadata": {
        "id": "-ApxoyEYrAWG"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "    z_clipped = np.clip(z, -500, 500)\n",
        "    return 1 / (1 + np.exp(-z_clipped))"
      ],
      "metadata": {
        "id": "AMqIREC9r6YP"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cost(theta, X, y):\n",
        "  m = len(y)\n",
        "\n",
        "  y = y.reshape(-1, 1) if y.ndim == 1 else y\n",
        "\n",
        "  h = sigmoid(np.dot(X, theta))\n",
        "  epsilon = 1e-10\n",
        "\n",
        "  h = np.clip(h, epsilon, 1 - epsilon)\n",
        "\n",
        "  J = (-1/m) * np.sum(y * np.log(h) + (1 - y) * np.log(1 - h))\n",
        "\n",
        "  grad = (1/m) * np.dot(X.T, (h - y))\n",
        "\n",
        "  return J, grad"
      ],
      "metadata": {
        "id": "5Zk3jADBsFmz"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initial_theta = np.zeros(X.shape[1]+1).reshape(X.shape[1]+1, 1)\n",
        "\n",
        "def gradient_descent(\n",
        "    X,\n",
        "    y,\n",
        "    theta = initial_theta,\n",
        "    alpha = 0.01,\n",
        "    num_iterations = 1500):\n",
        "  m, n_plus_1 = X.shape\n",
        "  theta = np.zeros((n_plus_1, 1))\n",
        "\n",
        "  J_history = []\n",
        "\n",
        "  y = y.reshape(-1, 1) if y.ndim == 1 else y\n",
        "\n",
        "  for iteration in range(num_iterations):\n",
        "    J, grad = cost(theta, X, y)\n",
        "    theta = theta - alpha * grad\n",
        "    J_history.append(J)\n",
        "\n",
        "  return theta, J_history"
      ],
      "metadata": {
        "id": "r52WhkuqougT"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(X, y, alpha=0.01, num_iterations=1500):\n",
        "    num_classes = len(np.unique(y))\n",
        "    all_theta = []\n",
        "\n",
        "    for c in range(num_classes):\n",
        "        y_c = (y == c).astype(int)\n",
        "        theta_c, _ = gradient_descent(X, y_c, alpha, num_iterations)\n",
        "        all_theta.append(theta_c)\n",
        "\n",
        "    return np.array(all_theta).reshape(num_classes, X.shape[1], 1)"
      ],
      "metadata": {
        "id": "SzWiHJOFrzE8"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(X, all_theta):\n",
        "  num_classes = all_theta.shape[0]\n",
        "  probabilities = np.array([sigmoid(np.dot(X, all_theta[c])) for c in range(num_classes)])\n",
        "  predictions = np.argmax(probabilities, axis=0)\n",
        "\n",
        "  return predictions.flatten()"
      ],
      "metadata": {
        "id": "AHGDNvbqsNt9"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "K = 5\n",
        "skf = StratifiedKFold(n_splits=K, shuffle=True, random_state=42)\n",
        "\n",
        "formatted_datasets = {\n",
        "    \"Normalized\": X_normalized_bias,\n",
        "    \"Standardized\": X_standardized_bias\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "for name, X_data in formatted_datasets.items():\n",
        "  fold_accuracies = []\n",
        "  fold_confusion_matrices = []\n",
        "\n",
        "\n",
        "  for fold, (train_index, test_index) in enumerate(skf.split(X_data, y)):\n",
        "    X_train, X_test = X_data[train_index], X_data[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    trained_all_theta = train(X_train, y_train)\n",
        "    y_pred = predict(X_test, trained_all_theta)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    fold_accuracies.append(accuracy)\n",
        "\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    fold_confusion_matrices.append(cm)\n",
        "\n",
        "    print(f\"Fold {fold+1}:\")\n",
        "    print(f\"  Acurácia: {accuracy:.4f}\")\n",
        "    print(\"  Matriz de Confusão:\")\n",
        "    print(cm)\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    avg_accuracy = np.mean(fold_accuracies)\n",
        "    results[name] = {\n",
        "        \"acuracias\": fold_accuracies,\n",
        "        \"acuracia_media\": avg_accuracy,\n",
        "        \"matrizes_confusao\": fold_confusion_matrices\n",
        "    }\n",
        "    print(f\"Acurácia Média para o Dataset {name}: {avg_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9ZVeq4osXH7",
        "outputId": "ec22f2cf-a1a1-4213-a9d0-d624a408e66c"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1:\n",
            "  Acurácia: 0.8333\n",
            "  Matriz de Confusão:\n",
            "[[10  0  0]\n",
            " [ 0  9  1]\n",
            " [ 0  4  6]]\n",
            "------------------------------\n",
            "Acurácia Média para o Dataset Normalized: 0.8333\n",
            "Fold 2:\n",
            "  Acurácia: 0.7667\n",
            "  Matriz de Confusão:\n",
            "[[10  0  0]\n",
            " [ 4  3  3]\n",
            " [ 0  0 10]]\n",
            "------------------------------\n",
            "Acurácia Média para o Dataset Normalized: 0.8000\n",
            "Fold 3:\n",
            "  Acurácia: 0.7000\n",
            "  Matriz de Confusão:\n",
            "[[9 1 0]\n",
            " [0 9 1]\n",
            " [0 7 3]]\n",
            "------------------------------\n",
            "Acurácia Média para o Dataset Normalized: 0.7667\n",
            "Fold 4:\n",
            "  Acurácia: 0.7667\n",
            "  Matriz de Confusão:\n",
            "[[10  0  0]\n",
            " [ 1  3  6]\n",
            " [ 0  0 10]]\n",
            "------------------------------\n",
            "Acurácia Média para o Dataset Normalized: 0.7667\n",
            "Fold 5:\n",
            "  Acurácia: 0.7667\n",
            "  Matriz de Confusão:\n",
            "[[10  0  0]\n",
            " [ 0 10  0]\n",
            " [ 0  7  3]]\n",
            "------------------------------\n",
            "Acurácia Média para o Dataset Normalized: 0.7667\n",
            "Fold 1:\n",
            "  Acurácia: 0.8667\n",
            "  Matriz de Confusão:\n",
            "[[10  0  0]\n",
            " [ 0  6  4]\n",
            " [ 0  0 10]]\n",
            "------------------------------\n",
            "Acurácia Média para o Dataset Standardized: 0.8667\n",
            "Fold 2:\n",
            "  Acurácia: 0.8333\n",
            "  Matriz de Confusão:\n",
            "[[10  0  0]\n",
            " [ 0 10  0]\n",
            " [ 0  5  5]]\n",
            "------------------------------\n",
            "Acurácia Média para o Dataset Standardized: 0.8500\n",
            "Fold 3:\n",
            "  Acurácia: 0.6000\n",
            "  Matriz de Confusão:\n",
            "[[10  0  0]\n",
            " [ 1  8  1]\n",
            " [ 0 10  0]]\n",
            "------------------------------\n",
            "Acurácia Média para o Dataset Standardized: 0.7667\n",
            "Fold 4:\n",
            "  Acurácia: 0.7667\n",
            "  Matriz de Confusão:\n",
            "[[10  0  0]\n",
            " [ 0  4  6]\n",
            " [ 0  1  9]]\n",
            "------------------------------\n",
            "Acurácia Média para o Dataset Standardized: 0.7667\n",
            "Fold 5:\n",
            "  Acurácia: 0.7667\n",
            "  Matriz de Confusão:\n",
            "[[10  0  0]\n",
            " [ 0 10  0]\n",
            " [ 0  7  3]]\n",
            "------------------------------\n",
            "Acurácia Média para o Dataset Standardized: 0.7667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, data in results.items():\n",
        "    print(f\"\\nDataset: {name}\")\n",
        "    print(f\"Acurácias Individuais por Fold: {[f'{acc:.4f}' for acc in data['acuracias']]}\")\n",
        "    print(f\"Acurácia Média: {data['acuracia_media']:.4f}\")\n",
        "    print(\"Matrizes de Confusão para cada Fold:\")\n",
        "    for i, cm in enumerate(data['matrizes_confusao']):\n",
        "        print(f\"Fold {i+1}:\\n{cm}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUErtP9uts65",
        "outputId": "5738a337-57e3-4b22-af40-5a5e2f9248ad"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset: Normalized\n",
            "Acurácias Individuais por Fold: ['0.8333', '0.7667', '0.7000', '0.7667', '0.7667']\n",
            "Acurácia Média: 0.7667\n",
            "Matrizes de Confusão para cada Fold:\n",
            "Fold 1:\n",
            "[[10  0  0]\n",
            " [ 0  9  1]\n",
            " [ 0  4  6]]\n",
            "Fold 2:\n",
            "[[10  0  0]\n",
            " [ 4  3  3]\n",
            " [ 0  0 10]]\n",
            "Fold 3:\n",
            "[[9 1 0]\n",
            " [0 9 1]\n",
            " [0 7 3]]\n",
            "Fold 4:\n",
            "[[10  0  0]\n",
            " [ 1  3  6]\n",
            " [ 0  0 10]]\n",
            "Fold 5:\n",
            "[[10  0  0]\n",
            " [ 0 10  0]\n",
            " [ 0  7  3]]\n",
            "\n",
            "Dataset: Standardized\n",
            "Acurácias Individuais por Fold: ['0.8667', '0.8333', '0.6000', '0.7667', '0.7667']\n",
            "Acurácia Média: 0.7667\n",
            "Matrizes de Confusão para cada Fold:\n",
            "Fold 1:\n",
            "[[10  0  0]\n",
            " [ 0  6  4]\n",
            " [ 0  0 10]]\n",
            "Fold 2:\n",
            "[[10  0  0]\n",
            " [ 0 10  0]\n",
            " [ 0  5  5]]\n",
            "Fold 3:\n",
            "[[10  0  0]\n",
            " [ 1  8  1]\n",
            " [ 0 10  0]]\n",
            "Fold 4:\n",
            "[[10  0  0]\n",
            " [ 0  4  6]\n",
            " [ 0  1  9]]\n",
            "Fold 5:\n",
            "[[10  0  0]\n",
            " [ 0 10  0]\n",
            " [ 0  7  3]]\n"
          ]
        }
      ]
    }
  ]
}